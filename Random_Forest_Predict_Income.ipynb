{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.tools.tools as stattools\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Datasets\n",
    "adult_train = pd.read_csv(\"/Users/datascience/Desktop/ADS 502 Data Sets/Website Data Sets/adult_ch6_training.csv\")\n",
    "adult_test = pd.read_csv(\"/Users/datascience/Desktop/ADS 502 Data Sets/Website Data Sets/adult_ch6_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Use random forests on the training data set to predict income using marital status and capital gains and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '<=50K', '<=50K', ..., '<=50K', '<=50K', '<=50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training Set ##\n",
    "# Separate X and Y Variables\n",
    "y = adult_train[['Income']]\n",
    "X = adult_train[['Marital status', 'Cap_Gains_Losses']]\n",
    "#Specify y names\n",
    "y_names = [\"<=50k\", \">50K\"]\n",
    "\n",
    "# Convert categorical variable into a dummy variable form\n",
    "mar_dummy = pd.get_dummies(X['Marital status'])\n",
    "\n",
    "#Add dummy variables back into X variables\n",
    "X = pd.concat((X[['Cap_Gains_Losses']], mar_dummy), axis = 1) #Column-wise Concatation (axis=1)\n",
    "\n",
    "#response variable as 1-D Array\n",
    "rfy = np.ravel(y)\n",
    "\n",
    "#Random Forest Classifier\n",
    "rfo1 = RandomForestClassifier(n_estimators = 100, criterion = \"gini\").fit(X, rfy)\n",
    "\n",
    "#Predictions\n",
    "R1 = rfo1.predict(X)\n",
    "rfo1.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Use random forests using the test data set that utilizes the same target and predictor variables. Does the test data result match the training data result?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K', '<=50K', ..., '<=50K', '<=50K', '<=50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TEST SET ##\n",
    "# Separate X and Y Variables\n",
    "y_test = adult_test[['Income']]\n",
    "X_test = adult_test[['Marital status', 'Cap_Gains_Losses']]\n",
    "#Specify y names\n",
    "y_test_names = [\"<=50k\", \">50K\"]\n",
    "\n",
    "# Convert categorical variable into a dummy variable form\n",
    "mar_dummy_test = pd.get_dummies(X_test['Marital status'])\n",
    "\n",
    "#Add dummy variables back into X variables\n",
    "X_test = pd.concat((X_test[['Cap_Gains_Losses']], mar_dummy_test), axis = 1) #Column-wise Concatation (axis=1)\n",
    "\n",
    "#response variable as 1-D Array\n",
    "rfy_test = np.ravel(y_test)\n",
    "\n",
    "#Random Forest Classifier\n",
    "rfo2 = RandomForestClassifier(n_estimators = 100, criterion = \"gini\").fit(X_test, rfy_test)\n",
    "\n",
    "#Predictions\n",
    "R2 = rfo2.predict(X_test)\n",
    "rfo2.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Training Data Set-- \n",
      "Accuracy:  0.8309258568306593 \n",
      "Error Rate:  0.16907414316934066 \n",
      "Sensitivity/Recall:  0.3011135857461025 \n",
      "Specificity:  0.9976175460724547 \n",
      "Precision:  0.9754689754689755\n",
      "\n",
      "---Testing Data Set-- \n",
      "Accuracy:  0.8309258568306593 \n",
      "Error Rate:  0.16907414316934066 \n",
      "Sensitivity/Recall:  0.3011135857461025 \n",
      "Specificity:  0.9976175460724547 \n",
      "Precision:  0.9754689754689755\n"
     ]
    }
   ],
   "source": [
    "# Validate Training Model using a confusion Matrix \n",
    "cm = confusion_matrix(y, R1)\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation Measures ###\n",
    "TAN = TN + FP\n",
    "TAP = FN + TP\n",
    "TPN = TN + FN\n",
    "TPP =  FP + TP\n",
    "GT = TN + FP + FN + TP\n",
    "\n",
    "# Accuracy\n",
    "Acc = (TN + TP) / (GT)\n",
    "# Error Rate\n",
    "Error = 1 - Acc\n",
    "# Sensitivity / Recall\n",
    "Sens = TP / TAP\n",
    "#Specificity\n",
    "Spec = TN/ TAN\n",
    "# Precision\n",
    "Prec = TP/TPP\n",
    "print('--Training Data Set--','\\nAccuracy: ', Acc, '\\nError Rate: ', Error, '\\nSensitivity/Recall: ', Sens, \n",
    "      '\\nSpecificity: ', Spec, '\\nPrecision: ', Prec)\n",
    "\n",
    "# Validate Testing Model using a confusion Matrix \n",
    "cm2 = confusion_matrix(y_test, R2)\n",
    "TN2 = cm[0][0]\n",
    "FP2 = cm[0][1]\n",
    "FN2 = cm[1][0]\n",
    "TP2 = cm[1][1]\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation Measures ###\n",
    "TAN2 = TN2 + FP2\n",
    "TAP2 = FN2 + TP2\n",
    "TPN2 = TN2 + FN2\n",
    "TPP2 =  FP2 + TP2\n",
    "GT2 = TN2 + FP2 + FN2 + TP2\n",
    "\n",
    "# Accuracy\n",
    "Acc2 = (TN2 + TP2) / (GT2)\n",
    "# Error Rate\n",
    "Error2 = 1 - Acc2\n",
    "# Sensitivity / Recall\n",
    "Sens2 = TP2 / TAP2\n",
    "#Specificity\n",
    "Spec2 = TN2/ TAN2\n",
    "# Precision\n",
    "Prec2 = TP2/TPP2\n",
    "print('\\n---Testing Data Set--', '\\nAccuracy: ', Acc2, '\\nError Rate: ', Error2, '\\nSensitivity/Recall: ', Sens2,\n",
    "      '\\nSpecificity: ', Spec2, '\\nPrecision: ', Prec2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Evaluation metrics, the testing data set matches with the training data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
